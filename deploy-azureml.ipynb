{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlflow.azureml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-638e58f4da5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mazureml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWorkspace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwebservice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAciWebservice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWebservice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlflow.azureml'"
     ]
    }
   ],
   "source": [
    "import mlflow.azureml\n",
    "\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "\n",
    "# Create or load an existing Azure ML workspace. You can also load an existing workspace using\n",
    "# Workspace.get(name=\"<workspace_name>\")\n",
    "workspace_name = \"mlflow-demo-deploy\"\n",
    "subscription_id = \"fb598598-1e1c-4197-b4ad-dec397c8be02\"\n",
    "resource_group = \"mlflow-demo\"\n",
    "location = \"northeurope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_workspace = Workspace.create(name=workspace_name,\n",
    "                                   subscription_id=subscription_id,\n",
    "                                   resource_group=resource_group,\n",
    "                                   location=location,\n",
    "                                   create_resource_group=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_workspace = Workspace.get(name=workspace_name,\n",
    "                                   subscription_id=subscription_id,\n",
    "                                   resource_group=resource_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an Azure ML container image for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model mlflow-afnexpicrymzmc9nvtpz7a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019/05/26 16:46:02 INFO mlflow.azureml: Registered an Azure Model with name: `mlflow-afnexpicrymzmc9nvtpz7a` and version: `1`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019/05/26 16:46:09 INFO mlflow.azureml: Building an Azure Container Image with name: `mlflow-sut-a-ocshyqpem-mhrg6w` and version: `1`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running........................................................................................\n",
      "Succeeded\n",
      "Image creation operation finished for image mlflow-sut-a-ocshyqpem-mhrg6w:1, operation \"Succeeded\"\n",
      "Access the following URI for build logs: https://mlflowdestorage575e01707.blob.core.windows.net/azureml/ImageLogs/86e20bda-ca08-42f4-a454-eaa05ee92654/build.log?sv=2018-03-28&sr=b&sig=t6XJ%2FU%2FqyoUtnNcyIA2ekUC8vx5NwUYfBb9oqxrIgqA%3D&st=2019-05-26T14%3A49%3A09Z&se=2019-06-25T14%3A54%3A09Z&sp=rl\n"
     ]
    }
   ],
   "source": [
    "azure_image, azure_model = mlflow.azureml.build_image(model_path=\"mlruns/0/6f2643b3af884323b05ada563a7a89f8/artifacts/models/\",\n",
    "                                                      workspace=azure_workspace,\n",
    "                                                      description=\"Text Classifier\",\n",
    "                                                      synchronous=True)\n",
    "# If your image build failed, you can access build logs at the following URI:\n",
    "print(\"Access the following URI for build logs: {}\".format(azure_image.image_build_log_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the container image to Azure Container Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating service\n"
     ]
    }
   ],
   "source": [
    "webservice_deployment_config = AciWebservice.deploy_configuration()\n",
    "webservice = Webservice.deploy_from_image(\n",
    "                    image=azure_image, workspace=azure_workspace, name=\"mlflowdemo2\")\n",
    "webservice.wait_for_deployment()\n",
    "\n",
    "# After the image deployment completes, requests can be posted via HTTP to the new ACI\n",
    "# webservice's scoring URI. The following example posts a sample input from the wine dataset\n",
    "# used in the MLflow ElasticNet example:\n",
    "# https://github.com/mlflow/mlflow/tree/master/examples/sklearn_elasticnet_wine\n",
    "print(\"Scoring URI is: %s\", webservice.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-26T04:39:14,110932388+00:00 - gunicorn/run \n",
      "2019-05-26T04:39:14,110428376+00:00 - rsyslog/run \n",
      "2019-05-26T04:39:14,111411599+00:00 - iot-server/run \n",
      "2019-05-26T04:39:14,111909610+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2019-05-26T04:39:22,851027573+00:00 - iot-server/finish 1 0\n",
      "2019-05-26T04:39:22,953492373+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.6.0\n",
      "Listening at: http://127.0.0.1:9090 (11)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 42\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "2019-05-26 04:40:15,956 | azureml.core.run | DEBUG | Could not load run context Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run., switching offline: False\n",
      "2019-05-26 04:40:15,956 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\n",
      "2019-05-26 04:40:15,956 | azureml.core.model | DEBUG | RunEnvironmentException: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "2019-05-26 04:40:15,956 | azureml.core.model | DEBUG | Using passed in version 1\n",
      "2019-05-26 04:40:15,957 | azureml.core.model | DEBUG | Found model path at azureml-models/mlflow-fpr19davt22b9lab9dfkzsw/1/models\n",
      "2019/05/26 04:40:15 WARNING mlflow.pyfunc: The version of Python that the model was saved in, `Python 3.7.0`, differs from the version of Python that is currently running, `Python 3.6.8`, and may be incompatible\n",
      "Users's init has completed successfully\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "Validation Request Content-Type\n",
      "Received input: {\"columns\": [\"description\"], \"data\": [[\"MAchine learning artificial intellingence computer\"]]}\n",
      "Headers passed in (total 11):\n",
      "\tHost: localhost:5001\n",
      "\tX-Real-Ip: 127.0.0.1\n",
      "\tX-Forwarded-For: 127.0.0.1\n",
      "\tX-Forwarded-Proto: http\n",
      "\tConnection: close\n",
      "\tContent-Length: 94\n",
      "\tUser-Agent: python-requests/2.22.0\n",
      "\tAccept: */*\n",
      "\tAccept-Encoding: gzip, deflate\n",
      "\tContent-Type: application/json\n",
      "\tX-Ms-Request-Id: 1e511a20-ee3d-4ca5-922c-dd362843e2c4\n",
      "Scoring Timer is set to 3600.0 seconds\n",
      "                                         description\n",
      "0  MAchine learning artificial intellingence comp...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "XXX lineno: 32, opcode: 160\n",
      "Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/var/azureml-app/app.py\", line 207, in run_scoring\n",
      "    response = invoke_user_with_timer(service_input, request_headers)\n",
      "  File \"/var/azureml-app/app.py\", line 275, in invoke_user_with_timer\n",
      "    result = user_main.run(**params)\n",
      "  File \"/var/azureml-app/main.py\", line 46, in run\n",
      "    return_obj = driver_module.run(**arguments)\n",
      "  File \"execution_script.py\", line 18, in run\n",
      "    return get_jsonable_obj(model.predict(input_df), pandas_orient=\"records\")\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/mlflow/pyfunc/model.py\", line 248, in predict\n",
      "    return self.python_model.predict(self.context, model_input)\n",
      "  File \"train.py\", line 32, in predict\n",
      "SystemError: unknown opcode\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/var/azureml-app/app.py\", line 124, in score_realtime\n",
      "    return run_scoring(service_input, request.headers)\n",
      "  File \"/var/azureml-app/app.py\", line 219, in run_scoring\n",
      "    raise RunFunctionException(str(exc))\n",
      "run_function_exception.RunFunctionException\n",
      "\n",
      "500\n",
      "127.0.0.1 - - [26/May/2019:04:41:11 +0000] \"POST /score HTTP/1.0\" 500 14 \"-\" \"python-requests/2.22.0\"\n",
      "Validation Request Content-Type\n",
      "Received input: {\"columns\": [\"description\"], \"data\": [[\"MAchine learning artificial intellingence computer\"]]}\n",
      "Headers passed in (total 12):\n",
      "\tHost: localhost:5001\n",
      "\tX-Real-Ip: 127.0.0.1\n",
      "\tX-Forwarded-For: 127.0.0.1\n",
      "\tX-Forwarded-Proto: http\n",
      "\tConnection: close\n",
      "\tContent-Length: 94\n",
      "\tUser-Agent: python-requests/2.22.0\n",
      "\tAccept: */*\n",
      "\tAccept-Encoding: gzip, deflate\n",
      "\tContent-Type: application/json\n",
      "\tFormat: pandas-split\n",
      "\tX-Ms-Request-Id: 8d7c422f-72d6-439d-a80f-c9d6e9a6de47\n",
      "Scoring Timer is set to 3600.0 seconds\n",
      "                                         description\n",
      "0  MAchine learning artificial intellingence comp...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "XXX lineno: 32, opcode: 160\n",
      "Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/var/azureml-app/app.py\", line 207, in run_scoring\n",
      "    response = invoke_user_with_timer(service_input, request_headers)\n",
      "  File \"/var/azureml-app/app.py\", line 275, in invoke_user_with_timer\n",
      "    result = user_main.run(**params)\n",
      "  File \"/var/azureml-app/main.py\", line 46, in run\n",
      "    return_obj = driver_module.run(**arguments)\n",
      "  File \"execution_script.py\", line 18, in run\n",
      "    return get_jsonable_obj(model.predict(input_df), pandas_orient=\"records\")\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/mlflow/pyfunc/model.py\", line 248, in predict\n",
      "    return self.python_model.predict(self.context, model_input)\n",
      "  File \"train.py\", line 32, in predict\n",
      "SystemError: unknown opcode\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/var/azureml-app/app.py\", line 124, in score_realtime\n",
      "    return run_scoring(service_input, request.headers)\n",
      "  File \"/var/azureml-app/app.py\", line 219, in run_scoring\n",
      "    raise RunFunctionException(str(exc))\n",
      "run_function_exception.RunFunctionException\n",
      "\n",
      "500\n",
      "127.0.0.1 - - [26/May/2019:04:45:24 +0000] \"POST /score HTTP/1.0\" 500 14 \"-\" \"python-requests/2.22.0\"\n",
      "Validation Request Content-Type\n",
      "Received input: {\"columns\":[\"description\"],\"data\":[[\"medicine engineering\"],[\"test medicine\"]]}\n",
      "Headers passed in (total 11):\n",
      "\tHost: localhost:5001\n",
      "\tX-Real-Ip: 127.0.0.1\n",
      "\tX-Forwarded-For: 127.0.0.1\n",
      "\tX-Forwarded-Proto: http\n",
      "\tConnection: close\n",
      "\tContent-Length: 79\n",
      "\tUser-Agent: curl/7.64.0\n",
      "\tAccept: */*\n",
      "\tContent-Type: application/json; format=pandas-split\n",
      "\tX-Ms-Request-Id: c22abd04-47a9-4607-958c-99bb98f82d54\n",
      "\tAccept-Encoding: gzip\n",
      "Scoring Timer is set to 3600.0 seconds\n",
      "            description\n",
      "0  medicine engineering\n",
      "1         test medicine\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "XXX lineno: 32, opcode: 160\n",
      "Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/var/azureml-app/app.py\", line 207, in run_scoring\n",
      "    response = invoke_user_with_timer(service_input, request_headers)\n",
      "  File \"/var/azureml-app/app.py\", line 275, in invoke_user_with_timer\n",
      "    result = user_main.run(**params)\n",
      "  File \"/var/azureml-app/main.py\", line 46, in run\n",
      "    return_obj = driver_module.run(**arguments)\n",
      "  File \"execution_script.py\", line 18, in run\n",
      "    return get_jsonable_obj(model.predict(input_df), pandas_orient=\"records\")\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/mlflow/pyfunc/model.py\", line 248, in predict\n",
      "    return self.python_model.predict(self.context, model_input)\n",
      "  File \"train.py\", line 32, in predict\n",
      "SystemError: unknown opcode\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/var/azureml-app/app.py\", line 124, in score_realtime\n",
      "    return run_scoring(service_input, request.headers)\n",
      "  File \"/var/azureml-app/app.py\", line 219, in run_scoring\n",
      "    raise RunFunctionException(str(exc))\n",
      "run_function_exception.RunFunctionException\n",
      "\n",
      "500\n",
      "127.0.0.1 - - [26/May/2019:04:46:36 +0000] \"POST /score HTTP/1.0\" 500 14 \"-\" \"curl/7.64.0\"\n",
      "Validation Request Content-Type\n",
      "Received input: {\"columns\":[\"description\"],\"data\":[[\"medicine engineering\"],[\"test medicine\"]]}\n",
      "Headers passed in (total 11):\n",
      "\tHost: localhost:5001\n",
      "\tX-Real-Ip: 127.0.0.1\n",
      "\tX-Forwarded-For: 127.0.0.1\n",
      "\tX-Forwarded-Proto: http\n",
      "\tConnection: close\n",
      "\tContent-Length: 79\n",
      "\tUser-Agent: curl/7.64.0\n",
      "\tAccept: */*\n",
      "\tContent-Type: application/json; format=pandas-split\n",
      "\tX-Ms-Request-Id: 2bfc115e-09db-4756-b1b3-cb91e5d21e30\n",
      "\tAccept-Encoding: gzip\n",
      "Scoring Timer is set to 3600.0 seconds\n",
      "XXX lineno: 32, opcode: 160\n",
      "            description\n",
      "0  medicine engineering\n",
      "1         test medicine\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/var/azureml-app/app.py\", line 207, in run_scoring\n",
      "    response = invoke_user_with_timer(service_input, request_headers)\n",
      "  File \"/var/azureml-app/app.py\", line 275, in invoke_user_with_timer\n",
      "    result = user_main.run(**params)\n",
      "  File \"/var/azureml-app/main.py\", line 46, in run\n",
      "    return_obj = driver_module.run(**arguments)\n",
      "  File \"execution_script.py\", line 18, in run\n",
      "    return get_jsonable_obj(model.predict(input_df), pandas_orient=\"records\")\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/mlflow/pyfunc/model.py\", line 248, in predict\n",
      "    return self.python_model.predict(self.context, model_input)\n",
      "  File \"train.py\", line 32, in predict\n",
      "SystemError: unknown opcode\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/var/azureml-app/app.py\", line 124, in score_realtime\n",
      "    return run_scoring(service_input, request.headers)\n",
      "  File \"/var/azureml-app/app.py\", line 219, in run_scoring\n",
      "    raise RunFunctionException(str(exc))\n",
      "run_function_exception.RunFunctionException\n",
      "\n",
      "500\n",
      "127.0.0.1 - - [26/May/2019:04:46:59 +0000] \"POST /score HTTP/1.0\" 500 14 \"-\" \"curl/7.64.0\"\n",
      "Validation Request Content-Type\n",
      "Received input: {\"columns\": [\"description\"], \"data\": [[\"MAchine learning artificial intellingence computer\"]]}\n",
      "Headers passed in (total 12):\n",
      "\tHost: localhost:5001\n",
      "\tX-Real-Ip: 127.0.0.1\n",
      "\tX-Forwarded-For: 127.0.0.1\n",
      "\tX-Forwarded-Proto: http\n",
      "\tConnection: close\n",
      "\tContent-Length: 94\n",
      "\tUser-Agent: python-requests/2.22.0\n",
      "\tAccept: */*\n",
      "\tAccept-Encoding: gzip, deflate\n",
      "\tContent-Type: application/json\n",
      "\tFormat: pandas-split\n",
      "\tX-Ms-Request-Id: 8200d8fe-7530-47d7-9649-3ec4c3f2625f\n",
      "Scoring Timer is set to 3600.0 seconds\n",
      "                                         description\n",
      "0  MAchine learning artificial intellingence comp...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/var/azureml-app/app.py\", line 207, in run_scoring\n",
      "    response = invoke_user_with_timer(service_input, request_headers)\n",
      "  File \"/var/azureml-app/app.py\", line 275, in invoke_user_with_timer\n",
      "    result = user_main.run(**params)\n",
      "  File \"/var/azureml-app/main.py\", line 46, in run\n",
      "    return_obj = driver_module.run(**arguments)\n",
      "  File \"execution_script.py\", line 18, in run\n",
      "    return get_jsonable_obj(model.predict(input_df), pandas_orient=\"records\")\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/mlflow/pyfunc/model.py\", line 248, in predict\n",
      "    return self.python_model.predict(self.context, model_input)\n",
      "  File \"train.py\", line 32, in predict\n",
      "SystemError: unknown opcode\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/var/azureml-app/app.py\", line 124, in score_realtime\n",
      "    return run_scoring(service_input, request.headers)\n",
      "  File \"/var/azureml-app/app.py\", line 219, in run_scoring\n",
      "    raise RunFunctionException(str(exc))\n",
      "run_function_exception.RunFunctionException\n",
      "\n",
      "500\n",
      "127.0.0.1 - - [26/May/2019:04:47:51 +0000] \"POST /score HTTP/1.0\" 500 14 \"-\" \"python-requests/2.22.0\"\n",
      "XXX lineno: 32, opcode: 160\n",
      "Validation Request Content-Type\n",
      "Received input: {\"columns\": [\"description\"], \"data\": [\"MAchine learning artificial intellingence computer\"]}\n",
      "Headers passed in (total 12):\n",
      "\tHost: localhost:5001\n",
      "\tX-Real-Ip: 127.0.0.1\n",
      "\tX-Forwarded-For: 127.0.0.1\n",
      "\tX-Forwarded-Proto: http\n",
      "\tConnection: close\n",
      "\tContent-Length: 92\n",
      "\tUser-Agent: python-requests/2.22.0\n",
      "\tAccept: */*\n",
      "\tAccept-Encoding: gzip, deflate\n",
      "\tContent-Type: application/json\n",
      "\tFormat: pandas-split\n",
      "\tX-Ms-Request-Id: 67cfcd2a-e10c-4e84-b33b-9c5d32c277fc\n",
      "Scoring Timer is set to 3600.0 seconds\n",
      "                                         description\n",
      "0  MAchine learning artificial intellingence comp...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "XXX lineno: 32, opcode: 160\n",
      "Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/var/azureml-app/app.py\", line 207, in run_scoring\n",
      "    response = invoke_user_with_timer(service_input, request_headers)\n",
      "  File \"/var/azureml-app/app.py\", line 275, in invoke_user_with_timer\n",
      "    result = user_main.run(**params)\n",
      "  File \"/var/azureml-app/main.py\", line 46, in run\n",
      "    return_obj = driver_module.run(**arguments)\n",
      "  File \"execution_script.py\", line 18, in run\n",
      "    return get_jsonable_obj(model.predict(input_df), pandas_orient=\"records\")\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/mlflow/pyfunc/model.py\", line 248, in predict\n",
      "    return self.python_model.predict(self.context, model_input)\n",
      "  File \"train.py\", line 32, in predict\n",
      "SystemError: unknown opcode\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/var/azureml-app/app.py\", line 124, in score_realtime\n",
      "    return run_scoring(service_input, request.headers)\n",
      "  File \"/var/azureml-app/app.py\", line 219, in run_scoring\n",
      "    raise RunFunctionException(str(exc))\n",
      "run_function_exception.RunFunctionException\n",
      "\n",
      "500\n",
      "127.0.0.1 - - [26/May/2019:04:47:59 +0000] \"POST /score HTTP/1.0\" 500 14 \"-\" \"python-requests/2.22.0\"\n",
      "Received input: {}\n",
      "Headers passed in (total 12):\n",
      "\tHost: localhost:5001\n",
      "\tX-Real-Ip: 127.0.0.1\n",
      "\tX-Forwarded-For: 127.0.0.1\n",
      "\tX-Forwarded-Proto: http\n",
      "\tConnection: close\n",
      "\tUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.157 Safari/537.36\n",
      "\tAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\n",
      "\tAccept-Encoding: gzip, deflate\n",
      "\tAccept-Language: nb-NO,nb;q=0.9,no;q=0.8,nn;q=0.7,en-US;q=0.6,en;q=0.5\n",
      "\tReferer: http://localhost:8888/notebooks/meetup-mlflow/deploy-azureml.ipynb\n",
      "\tUpgrade-Insecure-Requests: 1\n",
      "\tX-Ms-Request-Id: a9e09392-1835-4424-976b-9def9a93daef\n",
      "Scoring Timer is set to 3600.0 seconds\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "XXX lineno: 32, opcode: 160\n",
      "Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/var/azureml-app/app.py\", line 207, in run_scoring\n",
      "    response = invoke_user_with_timer(service_input, request_headers)\n",
      "  File \"/var/azureml-app/app.py\", line 275, in invoke_user_with_timer\n",
      "    result = user_main.run(**params)\n",
      "  File \"/var/azureml-app/main.py\", line 46, in run\n",
      "    return_obj = driver_module.run(**arguments)\n",
      "  File \"execution_script.py\", line 18, in run\n",
      "    return get_jsonable_obj(model.predict(input_df), pandas_orient=\"records\")\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/mlflow/pyfunc/model.py\", line 248, in predict\n",
      "    return self.python_model.predict(self.context, model_input)\n",
      "  File \"train.py\", line 32, in predict\n",
      "SystemError: unknown opcode\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/var/azureml-app/app.py\", line 101, in get_prediction_realtime\n",
      "    return run_scoring(service_input, request.headers)\n",
      "  File \"/var/azureml-app/app.py\", line 219, in run_scoring\n",
      "    raise RunFunctionException(str(exc))\n",
      "run_function_exception.RunFunctionException\n",
      "\n",
      "500\n",
      "127.0.0.1 - - [26/May/2019:04:48:38 +0000] \"GET /score HTTP/1.0\" 500 14 \"http://localhost:8888/notebooks/meetup-mlflow/deploy-azureml.ipynb\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.157 Safari/537.36\"\n",
      "127.0.0.1 - - [26/May/2019:04:48:39 +0000] \"GET /favicon.ico HTTP/1.0\" 404 232 \"http://c7be32f7-a5ed-493c-9934-d472d65d5b1e.westus.azurecontainer.io/score\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.157 Safari/537.36\"\n",
      "Exception in worker process\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/arbiter.py\", line 557, in spawn_worker\n",
      "    worker.init_process()\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 132, in init_process\n",
      "    self.run()\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 124, in run\n",
      "    self.run_for_one(timeout)\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 83, in run_for_one\n",
      "    self.wait(timeout)\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 35, in wait\n",
      "    ret = select.select(self.wait_fds, [], [], timeout)\n",
      "  File \"/var/azureml-app/app.py\", line 246, in alarm_handler\n",
      "    raise TimeoutException(error_message)\n",
      "timeout_exception.TimeoutException\n",
      "Worker exiting (pid: 42)\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 45\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "2019-05-26 05:48:55,950 | azureml.core.run | DEBUG | Could not load run context Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run., switching offline: False\n",
      "2019-05-26 05:48:55,950 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\n",
      "2019-05-26 05:48:55,950 | azureml.core.model | DEBUG | RunEnvironmentException: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "2019-05-26 05:48:55,951 | azureml.core.model | DEBUG | Using passed in version 1\n",
      "2019-05-26 05:48:55,951 | azureml.core.model | DEBUG | Found model path at azureml-models/mlflow-fpr19davt22b9lab9dfkzsw/1/models\n",
      "2019/05/26 05:48:55 WARNING mlflow.pyfunc: The version of Python that the model was saved in, `Python 3.7.0`, differs from the version of Python that is currently running, `Python 3.6.8`, and may be incompatible\n",
      "Users's init has completed successfully\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(webservice.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# `sample_input` is a JSON-serialized pandas DataFrame with the `split` orientation\n",
    "\n",
    "def get_prediction(text_to_predict):\n",
    "    sample_input = [{\n",
    "        \"description\": text_to_predict\n",
    "    }]\n",
    "    print(json.dumps(sample_input))\n",
    "    response = requests.post(\n",
    "                  url=webservice.scoring_uri, data=json.dumps(sample_input),\n",
    "                  headers={\"Content-type\": \"application/json\",\n",
    "                          \"format\": \"pandas-split\"})\n",
    "    response_json = json.loads(response.text)\n",
    "    return response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"description\":\"MAchine learning artificial intellingence computer\"}]'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"description\":[\"MAchine learning artificial intellingence computer\"]}).to_json(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"description\": \"MAchine learning artificial intellingence computer\"}]\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-af47c5e97ba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MAchine learning artificial intellingence computer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-52bbeec9fd35>\u001b[0m in \u001b[0;36mget_prediction\u001b[0;34m(text_to_predict)\u001b[0m\n\u001b[1;32m     14\u001b[0m                   headers={\"Content-type\": \"application/json\",\n\u001b[1;32m     15\u001b[0m                           \"format\": \"pandas-split\"})\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mresponse_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlflow-demo/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlflow-demo/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlflow-demo/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "get_prediction(\"MAchine learning artificial intellingence computer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
